{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (1.1.2)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/keyuhe/anaconda3/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import glob\n",
    "\n",
    "def debug_code_with_gpt(file_content, api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-3.5-turbo\",\n",
    "            prompt=\"The provided Java code is buggy. Fix the bug, using minimal changes. \\\n",
    "            Do not reorganize. Do not optimize. Do not provide explanation or justification. \\\n",
    "            Format your code in markdown.\\n```\" + file_content,\n",
    "            max_tokens=1024  # Adjust as needed\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"Error during API call:\", e)\n",
    "        return None\n",
    "\n",
    "def process_files(source_directory, target_directory, api_key):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "\n",
    "    for file_path in glob.glob(os.path.join(source_directory, '*.java')):\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_content = file.read()\n",
    "\n",
    "        debugged_content = debug_code_with_gpt(file_content, api_key)\n",
    "\n",
    "        if debugged_content:\n",
    "            target_file_path = os.path.join(target_directory, os.path.basename(file_path))\n",
    "            with open(target_file_path, 'w') as file:\n",
    "                file.write(debugged_content)\n",
    "            print(f\"Debugged code written to {target_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = 'your-openai-api-key'  # Replace with your actual API key\n",
    "    source_dir = 'bug_codes'  # Source directory\n",
    "    target_dir = 'debugged_codes'  # Target directory\n",
    "\n",
    "    process_files(source_dir, target_dir, api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('API_KEY.txt', 'r') as file:\n",
    "    API_KEY = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello GPT-4!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8IiJfgnfFSymNZ9e7gF2KDJpVhpnF', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1699470947, model='gpt-4-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=13, total_tokens=22))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "  ],\n",
    "  max_tokens=4000\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
